<!-- ---
header-includes:
    - \usepackage[makeroom]{cancel}
--- -->

# Matrizes

Uma matriz $m \times n$ (lemos: "m por n") tem $m$ linhas, na horizontal, e $n$ colunas, na vertical. Também é comum usarmos $i \times j$, para indicar o tamanho ou  **Ordem** da matriz. 

Para indicar os elementos de uma matriz $M_{m\times n}$, usamos a mesma letra que indicamos a matriz, mas em caixa baixa. Ou seja, na matriz $M$ indicada abaixo, o elemento $m_{2,3}$ é o elemento dessa matriz que está na 2ª linha e 3ª coluna. Para indicar uma coluna ou linha genérica, utilizamos o termo "fileira".

$$
M_{m\times n}=
\begin{bmatrix}
    m_{1,1} & m_{1,2} & \dots & m_{1,n} \\
    m_{2,1} & m_{2,2} & \dots & m_{2,n} \\
    \vdots  & \vdots & \ddots & \vdots \\
    m_{m,1} & m_{m,2} & \dots & m_{m_n}
\end{bmatrix}
$$

## Igualdade de Matrizes

Duas matrizes são ditas iguais se, e somente se, elas têm os mesmo tamanho e todos os elementos correspondentes são iguais.

$$
A_{m\times n} = B_{o\times p} \rightleftarrows 
\newline
\begin{cases}
    a_{1,1} = b_{1,1} \\
    a_{2,1} = b_{2,1} \\
    \vdots  \\
    a_{m,n} = b_{m,n}\\
    m = o \\
    n = p
    
\end{cases}
$$

Alternatimente, é possível expressar a afirmação acima com uma notação matemática mais formal. Nos capítulos iniciais deste livro, oferecemos mais de uma notação para acostumar o leitor à escrita matemática, mas, em capítulos futuros, exibiremos exclusivamente a notação formal. Veja o exemplo:

$$
A_{m,n} = B_{o,p} \; \rightleftarrows \; m=o  \; \land \; n=p \; \land \; \forall i \in [1,m], \;\forall j \in [1,n], \; \; a_{i,j} = b_{i,j}
$$

Lê-se: "A matriz $A$, $m$ por $n$, é igual à matriz $B$, $o$ por $p$, se, e somente se, $m$ é igual a $o$ e $n$ é igual a $p$ e, para todo elemento $i$ pertencente ao conjuntno de 1 a $m$ e todo $j$ pertencente ao conjunto de 1 a $n$, o elemento $a$ $i,j$ é igual ao elemento $b$ $i,j$.

## Matriz Quadrada

Uma matriz é dita quadrada se, e somento se, o número de linhas é igual ao número de colunas. $A_{m,n}$ é quadrada $\rightleftarrows m=n$

Nas matrizes quadradas, há elementos que chamamos de diagonal principal e diagonal secundária.
#Aqui eu não soube colocar uma seta grandona indicando as diagonais e eu acho que seria terrível colocar a definição matemática porque é 100% não intuitiva, depois a gente vê como faz isso. 

## Matriz Nula

Uma matriz é dita nula se, e somente se, todos os seus elementos são iguais a zero. Alternativamente, A é nula $\rightleftarrows \forall a \in A, \; a = 0$ (lê-se: "A é nula se, e somente se, para todo elemento $a$ pertencente à matriz $A$, tal elemento é igual a $0$."). Como notação de uma matriz nula, utilizamos o próprio algarismo 0, mas com o índice correspondente ao tamanho da matriz.

$$
0_{3\times 2}=
\underbrace{\begin{bmatrix}
    0 & 0  \\
    0 & 0  \\
    0 & 0
\end{bmatrix}}_{2}\Bigg\} ~_{3}
$$


Por mais que seja possível diferenciar a matriz nula do número $0$ por conta do índice, recomendamos que sempre atentem-se a que tipo de objeto matemática estamos trabalhando. Posteriormente, quando trabalharmos com vetores e espaços vetoriais, encontraremos mais um objeto cuja notação é $0$. Sempre que possível, reforçaremos ou explicitaremos qual objeto estamos lidando, mas tal diferenciação não estará presente na maioria dos materiais que encontrará durante sua jornada acadêmica.

## Matriz Identidade

Uma matriz identidade é uma matriz quadrada com $1$'s em sua diagonal e $0$'s como outros elementos. É comum chamarmos a matriz identidade de ordem $n$, ou seja, com $n$ linhas e $n$ colunas, de $I_n$: 
$$
I_{1} = 
\begin{bmatrix}
1
\end{bmatrix}
$$

$$
I_{n} =
\begin{bmatrix}
    1 & 0 & \dots & 0 \\
    0 & 1 & \dots & 0 \\
    \vdots  & \vdots & \ddots & \vdots \\
    0 & 0 & \dots & 1_{(a_{n,n})}
\end{bmatrix}
$$

Esse nome, "identidade", fará mais sentido quando discutirmos multiplicação de matrizes.

## Soma e Subtração de Matrizes

Para somar ou subtrair matrizes, basta realizar a operação elemento por elemento, obtendo uma nova matriz:

$$
\begin{aligned}
    A_{i\times j}+B_{i\times j}&=
    \begin{bmatrix}
        a_{1,1} & a_{1,2} & \dots & a_{1,j} \\
        a_{2,1} & a_{2,2} & \dots & a_{2,j} \\
        \vdots  & \vdots & \ddots & \vdots \\
        a_{i,1} & a_{i,2} & \dots & a_{i,j}
    \end{bmatrix}
    +
    \begin{bmatrix}
        b_{1,1} & b_{1,2} & \dots & b_{1,j} \\
        b_{2,1} & b_{2,2} & \dots & b_{2,j} \\
        \vdots  & \vdots & \ddots & \vdots \\
        b_{i,1} & b_{i,2} & \dots & b_{i,j}
    \end{bmatrix}\\ \\
    &=
    \begin{bmatrix}
        a_{1,1} + b_{1,1} & a_{1,2} + b_{1,2} & \dots & a_{1,j} + b_{1,j} \\
        a_{2,1} + b_{2,1} & a_{2,2} + b_{2,2} & \dots & a_{2,j} + b_{2,j} \\
        \vdots  & \vdots & \ddots & \vdots \\
        a_{i,1} + b_{i,1} & a_{i,2} + b_{i,2} & \dots & a_{i,j} + b_{i,j}
    \end{bmatrix}
\end{aligned}
$$

Dessa forma, podemos nos perguntar o que aconteceria se tentássemos somar uma matriz $3\times 3$ por uma $2 \times 2$. Pode parecer intuitivo pensar que essa soma poderia ser feita, deixando a linha 3 e coluna 3 da primeira matriz intacta, mas esse pensamento está incorreto. **Aviso**: *Podemos apenas somar e subtraír matrizes de mesma ordem.*

## Multiplicação de matrizes por escalar

Chamamos de escalar um número (normalmente real, comumente chamado de $\lambda$) que multiplica um vetor ou matriz. Para multiplicar uma matriz por um escalar, multiplicamos todos seus elementos por ele, um a um, idependentemente da sua ordem. Isso recebe o nome de produto por escalar.

$$
\lambda~ M_{m\times n}=
\lambda~
\begin{bmatrix}
    a_{1,1} & a_{1,2} & \dots & a_{1,n} \\
    a_{2,1} & a_{2,2} & \dots & a_{2,n} \\
    \vdots  & \vdots & \ddots & \vdots \\
    a_{m,1} & a_{m,2} & \dots & a_{m,n}
\end{bmatrix}
=
\begin{bmatrix}
    \lambda a_{1,1} & \lambda a_{1,2} & \dots & \lambda a_{1,n} \\
    \lambda a_{2,1} & \lambda a_{2,2} & \dots & \lambda a_{2,n} \\
    \vdots  & \vdots & \ddots & \vdots \\
    \lambda a_{m,1} & \lambda a_{m,2} & \dots & \lambda a_{m,n}
\end{bmatrix}
$$

*Atenção*: Você pode já ter ouvido sobre **Produto Escalar**. Isso **não** é o produto de uma matriz por um escalar, mas sim uma operação distinta que estudaremos em algebra linear.

*Produto Escalar*: Operação entre duas matrizes (vetores) que nos dá um escalar 
*Produto POR Escalar*: Operação que acabamos de estudar entre matriz e um escalar que nos dá uma matriz.
Conforme dito anteriormente, compreender que tipo de objetos matemáticos estamos trabalhando e quais operações podemos efetuar com eles é fundamental para o estúdo do cálculo.

## Multiplicação de Matrizes

Para multiplicarmos duas matrizes, é necessário que o número de colunas da primeira matriz seja igual ao número de linhas da segunda matriz. Por esse e outros motivos, dizemos que a multiplicação de matrizes *não é comutativa*, ou seja, multiplicar uma matriz $M$ por uma matriz $N$ pode nos dar uma matriz resultante diferente do que se multiplicarmos $N$ por $M$, caso essa multiplicação seja se quer possível!

$$
\begin{aligned}
    M_{i\times j} \times N_{j\times k}, j=j \Rightarrow \checkmark \\
    M_{i\times j} \times B_{k\times j}, j\neq k \Rightarrow ✘ \\
    N_{j\times k} \times M_{i\times j}. k\neq i \Rightarrow ✘
\end{aligned}
$$

Vamos analisar como a operação é feita, e então nos ficará claro o porquê dessa regra existir.

Considere as seguintes matrizes:

$$
\begin{aligned}
    &A_{2\times 3} =
    \begin{bmatrix}
        1 & 2 & 3 \\
        4 & 5 & 6
    \end{bmatrix} \\ \\
    &B_{3\times 1} = 
    \begin{bmatrix}
        7 \\
        8 \\
        9
    \end{bmatrix}
\end{aligned}
$$

Sabemos que podemos multiplicá-las com A como primeira matriz $A_{2\times 3}\times B_{3\times 1}, 3=3\Rightarrow \checkmark$, mas não como segunda matriz: $B_{3\times 1} \times A_{2\times 3}, 1\neq 2 \Rightarrow ✘$. Iremos então realizar a primeira operação descrita da seguinte maneira:

*Definição.* Para multiplicar matrizes, somaremos cada linha da primeira multiplicada por um elemento equivalente de cada coluna:

$$
\begin{aligned}
    &A \times B \\
    &=
    \begin{bmatrix}
        1 & 2 & 3 \\
        4 & 5 & 6
    \end{bmatrix}
    \times 
    \begin{bmatrix}
        7 \\
        8 \\
        9
    \end{bmatrix}\\ \\
    &=
    \begin{bmatrix}
        1 \cdot 7 + 2 \cdot 8 + 3 \cdot 9 \\
        4 \cdot 7 + 5 \cdot 8 + 6 \cdot 9
    \end{bmatrix} \\ \\
    &=
    \begin{bmatrix}
        50 \\
        122
    \end{bmatrix}
\end{aligned}
$$

É importante que você se familiarize com o "pareamento" feito entre as linhas da primeira matriz com as linhas da segunda. Você pode agora estar se perguntando o que aconteceria caso houvesse mais de uma coluna na segunda matriz. A resposta pode ser bastante intuitiva para você: a matriz resultante terá mais uma coluna.

**Eu quero adicionar mais detalhes na multiplicação de matrizes, mas estou esboçando no papel a formatação. Pode enviar sem isso, mas eu vou mudar no futuro.**

$$
\begin{aligned}
    &C \times D  \\
    &= 
    \begin{bmatrix}
        a & b & c \\
        d & e & f
    \end{bmatrix}
    \times 
    \begin{bmatrix}
        g & h \\
        i & j\\
        k & l
    \end{bmatrix}\\  \\
    &=
    \begin{bmatrix}
        a \cdot g + b \cdot i + c \cdot k & a \cdot h + b \cdot j + c \cdot k\\
        d \cdot g + e \cdot i + f \cdot k & d \cdot h + e \cdot j + f \cdot k
    \end{bmatrix}
\end{aligned}
$$

Note que o número de linhas da matriz resultate da multiplicação entre matrizes é sempre igual ao número de linhas da primeira matriz e o de colunas igual ao da segunda. Ou seja, *Para multiplicarmos, os números de "dentro" devem ser iguais, e a matriz resultante terá dimensões iguais aos números de "fora"*: 

$$
M_{3\times 2} \times N_{2 \times 4} \stackrel{2=2}{=} H_{3 \times 4}
$$

------------------------------------------------------------------------

E onde a matriz identidade entra no jogo?

Para qualquer matriz $M_{i\times j}$,

$$
I_{i} \times M_{i\times j} = M_{i\times j} = M_{i\times j}\times I_{j}
$$

Prove!

------------------------------------------------------------------------

A multiplicação de matrizes, por mais que simples, é extremamente poderosa e é a base por trás de importantes conceitos matemáticos. Um deles é a inversão de matriz, que você verá adiante.

## Determinantes

Deteminantes são computações especiais realizadas em matrizes quadradas. Os determinantes possuem interpretações muito interessantes, sobretudo na geometria e são amplamente aplicados no estuda da álgbera linear, mas, por hora, apenas aprenderemos como calculá-los, especialmente até matrizes de ordem 3 e apresentaremos superficialmente métodos para calcular determinantes de ordem superior. Limitaremos o estudo aprofundado à ordem 3, pois o trabalho para calcular o determinante de matrizes de ordem maior do que 3 cresce exponencialmente e dificilmente será pedido ao aluno para fazer essas contas. Como diz a Profa. Dra. Mary Lilian, "Quem sabe teoria não faz conta".

O determinante de uma matriz de ordem 1 é, simplesmente, o valor nela contido: 

$$
\det{A_{1\times1}}=
\begin{vmatrix}
    3
\end{vmatrix} = 3
$$

onde $||$ representa o determinante, e não o módulo, da matriz com único elemento 3.

E para matrizes de maior ordem?

Seja 

$$
M_{2\times2} =
\begin{bmatrix}
    1 & 2\\
    3 & 4 
\end{bmatrix}
$$

Podemos calcular o determinante de M, $\det{M},\det{(M)}, |M|$, multiplicando a diagonal principal e subtraindo do produto da outra diagonal: 

$$
\det{(M)}=\begin{vmatrix}
    1 & 2\\
    3 & 4 
\end{vmatrix} = 1 \cdot 4 - (2 \cdot 3) = -2
$$

E quais seriam as "diagonais" de uma matriz de ordem 3?

Seja 

$$
N_{3\times3} =
\begin{bmatrix}
    1 & 2 & 3\\
    4 & 5 & 6\\
    7 & 8 & 9
\end{bmatrix}
$$

Podemos calcular seu determinante com algumas técnicas. A mais comum forma de lembramos desse método é a chamada *Fórmula de Leibniz para Determinantes*. Assim como nas matrizes de ordem 2, iremos somar os produtos das "diagonais principais" (esquerda para direita) e subtrair os produtos das "diagonais secundárias" (direita para esquerda). Para visualizarmos tais diagonais "escondidas" na matriz, usaremos a *Regra de Sarrus*: copiar as primeiras duas colunas à direita da matriz:

$$
\begin{aligned}
    |N_{3\times3}| &=
    \left|\begin{array}{ccc|cc}
        1 & 2 & 3 & 1 & 2 \\ 
        4 & 5 & 6 & 4 & 5 \\
        7 & 8 & 9 & 7 & 8
    \end{array}\right| \\
    &= (1 \cdot 5 \cdot 9 + 2 \cdot 6 \cdot 7 + 3 \cdot 4 \cdot 8) \\
    &- (2 \cdot 4 \cdot 9 + 1 \cdot 6 \cdot 8 + 3 \cdot 5 \cdot 7)\\
    &= 225 - 225 = 0
\end{aligned}
$$
Algumas versões da Regra de Sarrus copiam as duas primeiras linhas da matriz abaixo da matriz e efetuam um cálculo semelhante: somam as "diagonais principais" e  subtraem as "diagonais secundárias". Teste os dois métodos e verifique se há diferença dos resultados e quais são as diferenças no procedimento!

Existem outras formas de calcular determinantes. Para os leitores interesados, recomendamos que busquem a resolução de determinantes pelo *Teorema de Laplace*, também conhecido como expansão de cofatores. Esse é um poderoso teorema nos permite calcular determinantes de matrizes de ordem maior do que 3, além de também poder aplicado na matriz 3x3 para (algumas vezes) cálculos mais simples. A desvantagem deste método é que calcular o determinante cresce exponencialmente conforme a ordem da matriz cresce.
Um segundo método para calcular o determinante de matrizes quadradas é conhecido como *Regra de Chió*. Trata-se de um algoritmo que, em cada execução, diminui em um a ordem de uma matriz quadrada. Assim como o método anterior, este também apresenta um crescimento exponencial do trabalho necessário para calcular o determinante de matrizes de ordens superiores.

## Aqui eu queria incluir um quadrado, ou qualquer coisa que dê destaque para ensinarmos as pessoas a usarem um site para verificar o determinante 

### Propriedados dos determinantes

As propriedades listadas abaixo, apesar de serem válidas para todos os casos, não foram separadas em teoremas, lemas, corolários ou cossequências. Para demonstrações e separações mais rigorosas, recomendamos um livro de álgebra linear.
Todas as propriedades listadas abaixo podem ser verificadas calculando o determinante por meio de um dos métodos listados anteriormente. Note que verificar uma propriedade não é equivalente a prová-la, mas é interessante testar antes de adotá-las cegamente.

**1ª propriedade - Fila Nula**
Se todos os elementos de uma fila de uma matriz forem iguais a $0$, então o determinante dessa matriz também será igual a $0$.
Exemplos:
$$
A_{3\times3} =
\begin{bmatrix}
    0 & 2 & 3\\
    0 & 5 & 6\\
    0 & 8 & 9 \\
\end{bmatrix}
\rightarrow det(A) = 0
$$

$$
B_{3\times3} =
\begin{bmatrix}
    9 & 5 & 8\\
    0 & 0 & 0\\
    20 & 7 & -5 \\
\end{bmatrix}
\rightarrow det(B) = 0
$$

**2ª propriedade - Troca de Filas Paralelas**
Trocar duas linhas ou duas colunas inverte o sinal do determinante.
Exemplo:
$$
A_{3\times3} =
\begin{bmatrix}
    1 & 2 & 1\\
    2 & 1 & 1\\
    5 & -5 & 2 \\
\end{bmatrix} \\
\rightarrow det(A) = -6
$$
Trocando a primeira com a segunda linha:
$$
A'_{3\times3} =
\begin{bmatrix}
    2 & 1 & 1\\
    1 & 2 & 1\\
    5 & -5 & 2 \\
\end{bmatrix} \\
\rightarrow det(A') = 6
$$

**3ª propriedade - Multiplicação por Escalar**
Multiplicar uma das filas de uma matriz por um escalar também multiplica o determinante por esse mesmo escalar. Consequentemente, $det(\lambda M_{n,n}) = \lambda ^ n det(M_{n,n})$.
Exemplos:
$$
A_{3\times3} =
\begin{bmatrix}
    2 & 3 & 1  \\
    4 & 2 & -3 \\
    -1 & 0 & 2 \\
\end{bmatrix}  \\
\rightarrow det(A) = -5
$$
Multiplicando-se a primeira coluna de $A$ por 5:
$$
A'_{3\times3} =
\begin{bmatrix}
    10 & 3 & 1  \\
    20 & 2 & -3 \\
    -5 & 0 & 2 \\
\end{bmatrix}  \\
\rightarrow det(A') = -25
$$
Multiplicando-se a matriz $A$ por 2:
$$
2\cdot A_{3\times3} =
\begin{bmatrix}
    4 & 6 & 2  \\
    8 & 4 & -6 \\
    -2 & 0 & 4 \\
\end{bmatrix}  \\
\rightarrow det(2 \cdot A) = 2^3 \cdot det(A) = -40
$$

**4ª propriedade - Combinação Linear**
Multiplicar uma fileira por um escalar e somá-la a outra fileira não altera o determinante. Note que, tomando-se $\lambda$ negativo, é possível extender essa propriedade para a subtração.
Exemplo:
$$
A_{3\times3} =
\begin{bmatrix}
    3 & 2 & -1  \\
    -2 & 1 & 3 \\
    -2 & -3 & 1 \\
\end{bmatrix}  \\
\rightarrow det(A) = 14
$$
Multiplicando-se a primeira linha por -2 e somando-a à terceira linha:
$$
A'_{3\times3} =
\begin{bmatrix}
    3 & 2 & -1  \\
    -2 & 1 & 3 \\
    -8 & -7 & 3 \\
\end{bmatrix}  \\
\rightarrow det(A') = det(A) = 14
$$

**5ª propriedade - Proporcionalidade de Filas**
Se uma fila pode ser escrita como combinação linear de outras filas paralelas, o determinante é igual a $0$. Note que é simples demonstrar essa propriedade, pois se uma fila é combinação linear de outras filas paralelas, basta tomar o oposto dessa combinação linear para produzir uma fila nula. Particularmente, se duas filas são iguais ou proporcionais, é simples verificar que o determinante é igual a $0$.
Exemplo:
$$
A_{3\times3} =
\begin{bmatrix}
    -5 & 2 & 1  \\
    -10 & 8 & 2 \\
    10 & -3 & -2 \\
\end{bmatrix}  \\
\rightarrow det(A) = 0
$$
Note que a primeira coluna é igual à primeira fileira multiplicada por $-5$: $-5 = 1 \cdot -5$, $-10 = 2 \cdot -5$, $10 = -2 \cdot -5$.

**6ª propriedade - Determinante do Produto**
Sejam $A$ e $B$ matrizes quadradas de mesma ordem (e portanto multiplicáveis), $det(A \cdot B) = det(A) \cdot det(B)$.
Exemplo:
$$
A_{2\times2} =
\begin{bmatrix}
    4 & 1 \\
    2 & 3 \\
\end{bmatrix}  \\
\rightarrow det(A) = 10
$$
$$
B_{2\times2} =
\begin{bmatrix}
    3 & 0 \\
    1 & 2 \\
\end{bmatrix}  \\
\rightarrow det(B) = 6
$$
$$
A \cdot B =
\begin{bmatrix}
    4 & 1 \\
    2 & 3 \\
\end{bmatrix} 
\cdot
\begin{bmatrix}
    3 & 0 \\
    1 & 2 \\
\end{bmatrix}

\rightarrow det(A \cdot B) = det(A) \cdot det(B) = 10 \cdot 6 = 60
$$

**7ª propriedade - Matriz triangular**
Uma matriz quadrada é dita triangular se, e somente se, todos os elementos acima ou abaixo da diagonal principal são iguais a $0$. Neste caso, o determinante é igual ao produto de todos os elementos da diagonal principal.
Exemplo:
$$
A_{4\times4} =
\begin{bmatrix}
    -3 & 9 & \pi & 2  \\
    0 & -2 & 7 & \sqrt{2} \\
    0 & 0  & 2 & ln(5) \\
    0 & 0 & 0 & 1
\end{bmatrix}  \\
\rightarrow det(A) = -3 \cdot -2 \cdot 2 \cdot 1 = 12
$$


## Inversão de matrizes

Dizemos que uma matriz quadrada $M_{n\times n}$ é inversível se existe uma outra matriz, $N$, tal que: 

$$
    M\times N = N \times M = I_n
$$

### Escalonamento

Uma das formas de chegamos na matriz inversa é considerarmos os seguinte: $N$ pode ser escrita como o produto de outras matrizes.

$$
\begin{cases}
    M \times N = N \times M = I_{n} \\
    N = {A \times B}
\end{cases}\Rightarrow M \times (A \times B) = (A\times B) \times M = I_n 
$$

> Note que os parênteses aqui são desnecessários: por mais que a multiplicação de matrizes não seja comutativa, ela é associativa! (Recomendamos que prove essa propriedade).

Sabemos também que, pela propriedade da matriz identidade,

$$
A \times B = A \times B \times I_n = I_n \times A \times B
$$

Com esse recurso, podemos chegar na matriz inversa através de operações mais simples partindo de uma matriz como a identidade!

Antes de prosseguirmos, note uma interessante propriedade: *Uma matriz é inversível se, e somente se, seu determinante for diferente de* $0$. A razão disso não ficará clara agora, mas leitores interessados podem se referir à @sec-material-matrizes - Material Adicional.

Para utilizarmos a técnica do escalonamento, precisaremos primeiro definir 3 operações que nos serão de grande ajuda neste processo. O porquê dessas operações serem válidas nos ficará mais claro quando discutirmos sistemas lineares posteriormente neste livro.

*Operação 1.* No escalonamento, podemos trocar linhas da matriz de lugar. 

$$
\begin{bmatrix}
    1 & 2 \\
    3 & 4
\end{bmatrix} \stackrel{\text{Operação 1}}{\rightarrow}
\begin{bmatrix}
    3 & 4 \\
    1 & 2
\end{bmatrix}
$$

*Operação 2.* No escalonamento, podemos multiplicar qualquer linha por um número real $\lambda \neq 0$ 

$$
\begin{bmatrix}
    1 & 2 \\
    3 & 4
\end{bmatrix} \stackrel{\text{Operação 2: $-1\cdot$I}}{\rightarrow}
\begin{bmatrix}
    -1 & -2 \\
    3& 4
\end{bmatrix}
$$

*Operação 3.* No escalonamento, podemos somar linhas e substituílas pelo valor da soma

$$
\begin{bmatrix}
    1 & 2 \\
    3 & 4
\end{bmatrix} \stackrel{\text{Operação 3: I + II -> II}}{\rightarrow}
\begin{bmatrix}
    1 & 2 \\
    4 & 6
\end{bmatrix}
$$

Note que essas operações alteram a matriz, mas podem ser utilizadas no escalonamento, uma vez que podem ser traduzidas como multiplicações por outras matrizes e, como discutimos, podemos descontruir a matriz inversa como o produto de outras matrizes ($N=(A\times B)$)

------------------------------------------------------------------------

Curiosidade: Um exemplo de uma matriz que, quando muliplicamos, realiza uma dessas operações (no caso, a 1), é a seguinte:

Seja 

$$
V = \begin{bmatrix}
    a & b \\
    d & e \\
    g & h
\end{bmatrix}
$$

então a matriz que troca as linhas I e II de lugar pode ser descrita como

$$
\begin{bmatrix}
    0 & 1 & 0\\
    1 & 0 & 0\\
    0 & 0 & 1
\end{bmatrix}
$$

Tente resolver o produto 

$$
\begin{bmatrix}
    0 & 1 & 0\\
    1 & 0 & 0\\
    0 & 0 & 1
\end{bmatrix} 
\begin{bmatrix}
    a & b \\
    d & e \\
    g & h
\end{bmatrix}
$$

e verifique o resultado!

Você consegue encontrar outras matrizes que realizam as outras operações? Dica: todas essas matrizes são próximas da matriz identidade.

------------------------------------------------------------------------

Vamos partir para um exemplo de como inverter uma matriz.

Seja

$$
M = 
\begin{bmatrix}
    1 & 3 & 2 \\
    2 & 1 & 5 \\
    4 & 2 & 3
\end{bmatrix}
$$

Encorajamos o leitor a verificar que o determinante dessa matriz é difernete de 0, ou seja, é inversível.

Usaremos uma técnica de escalonamento que consiste em comparar nossa matriz original com a matriz identidade de mesma ordem, buscando transformá-la na matriz identidade matriz e catalogando nossas mudanças na segunda matriz que então se revelerá como inversa.

Lembre-se: nosso objetivo é agora transformar a matriz original na matriz identidade, ou seja, zerar todos os elementos que não sejam os da diagonal principal e tornar os elementos dessa 1.

Nossa estratégia será a seguinte: zerar todos os elementos fora da diagonal principal, coluna por coluna, e então transformar os elementos da diagonal principal em 1 através da operação 2. 

$$
\begin{aligned}
    &\left[\begin{array}{ccc|ccc}
        1 & 3 & 2 & 1 & 0 & 0 \\
        2 & 1 & 5 & 0 & 1 & 0 \\
        4 & 2 & 3 & 0 & 0 & 1
    \end{array}\right]  \stackrel{-2\cdot I}{\rightarrow}
    \left[\begin{array}{ccc|ccc}
        -2 & -6 & -4 & -2 & 0 & 0 \\
        2 & 1 & 5 & 0 & 1 & 0 \\
        4 & 2 & 3 & 0 & 0 & 1
    \end{array}\right] \\ \\
    \stackrel{I+II->II}{\rightarrow}
    &
    \left[\begin{array}{ccc|ccc}
        -2 & -6 & -4 & -2 & 0 & 0 \\
        0 & -5 & 1 & -2 & 1 & 0 \\
        4 & 2 & 3 & 0 & 0 & 1
    \end{array}\right] \\ \\
    \stackrel{I+III->III}{\rightarrow}
    &
    \left[\begin{array}{ccc|ccc}
        -4 & -12 & -8 & -4 & 0 & 0 \\
        0 & -5 & 1 & -2 & 1 & 0 \\
        0 & -10 & -5 & -4 & 0 & 1
    \end{array}\right] ~~\text{Zeramos a primeira coluna!} \\ \\
    \stackrel{-\frac{1}{4}\cdot I}{\rightarrow}
    &
    \left[\begin{array}{ccc|ccc}
        1 & 3 & 2 & 1 & 0 & 0 \\
        0 & -5 & 1 & -2 & 1 & 0 \\
        0 & -10 & -5 & -4 & 0 & 1
    \end{array}\right] \\ \\
    \stackrel{5\cdot I+3\cdot II -> I}{\rightarrow}
    &
    \left[\begin{array}{ccc|ccc}
        5 & 0 & 13 & -1 & 3 & 0 \\
        0 & -15 & 3 & -6 & 3 & 0 \\
        0 & -10 & -5 & -4 & 0 & 1
    \end{array}\right] \\ \\
    \stackrel{\frac{1}{3}II}{\rightarrow}
    &
    \left[\begin{array}{ccc|ccc}
        5 & 0 & 13 & -1 & 3 & 0 \\
        0 & -5 & 1 & -2 & 1 & 0 \\
        0 & -10 & -5 & -4 & 0 & 1
    \end{array}\right] \\ \\
    \stackrel{-2\cdot II + III -> III}{\rightarrow}
    &
    \left[\begin{array}{ccc|ccc}
        5 & 0 & 13 & -1 & 3 & 0 \\
        0 & 10 & -2 & 4 & -2 & 0 \\
        0 & 0 & -7 & 0 & -2 & 1
    \end{array}\right] ~~\text{Zeramos a segunda coluna!}\\ \\
    \stackrel{7\cdot I + 13\cdot III -> I}{\rightarrow}
    &
    \left[\begin{array}{ccc|ccc}
        35 & 0 & 0 & -7 & -5 & 13 \\
        0 & 10 & -2 & 4 & -2 & 0 \\
        0 & 0 & -91 & 0 & -26 & 13
    \end{array}\right]  \\ \\
    \stackrel{\frac{1}{13}\cdot III}{\rightarrow}
    &
    \left[\begin{array}{ccc|ccc}
        35 & 0 & 0 & -7 & -5 & 13 \\
        0 & 10 & -2 & 4 & -2 & 0 \\
        0 & 0 & -7 & 0 & -2 & 1
    \end{array}\right]  \\ \\
    \stackrel{-7\cdot II + 2 \cdot III -> II}{\rightarrow}
    &
    \left[\begin{array}{ccc|ccc}
        35 & 0 & 0 & -7 & -5 & 13 \\
        0 & -70 & 0 & -28 & 10 & 2 \\
        0 & 0 & -14 & 0 & -4 & 2
    \end{array}\right]\\ \\
    &\text{Podemos agora transformar os elementos da diagonal em 1.} \\ 
    \\
    \stackrel{\frac{1}{35}\cdot I, -\frac{1}{70} \cdot II, -\frac{1}{14} \cdot III}{\rightarrow}
    &
    \left[\begin{array}{ccc|ccc}
        1 & 0 & 0 & -\frac{7}{35} & -\frac{5}{35} & \frac{13}{35} \\
        0 & 1 & 0 & \frac{14}{35} & -\frac{5}{35} & -\frac{1}{35} \\
        0 & 0 & 1 & 0 & \frac{2}{7} & -\frac{1}{7}
    \end{array}\right]
\end{aligned}
$$

Portanto, finalmente, a matriz inversa de $M$ é

$$
N = 
\begin{bmatrix}
    -\frac{7}{35} & -\frac{5}{35} & \frac{13}{35} \\
    \frac{14}{35} & -\frac{5}{35} & -\frac{1}{35} \\
    0 &\frac{2}{7} & -\frac{1}{7}
\end{bmatrix}
$$

Caso esteja com muita vontade de fazer conta, o leitor pode verificar que $M\times N = I = N \times M$.

Nota: Detalhamos demasiadamente as operações sendo feitas duranto o processo de escalonamento. Quando estiver mais confiente, poderá realizar diversas operações ao mesmo tempo, como, por exemplo, ao invés de $-1\cdot I + II -> II, -1*I$, poderia simplesmente fazer $I-II->II$, uma vez que são equivalentes.

Leitores atentos podem ter percebido certo padrão em nossa estratégia de escalonamento, e isso não é coincidência: estamos usando uma forma do *Algorítmo ou Método de Gauss-Jordan* @sekhonSystemsLinearEquations2020.

Apenas enunciaremos o algoritmo aqui, mas recomendamos que leitores interessados busquem mais sobre sua origem, interessante história e sua prova.

**Método de Gauss-Jordan**

1.  Troque as linhas para obter um elemento não-nulo na posição 1,1 da matriz pela operação 1;

2.  Use a operação 2 para transformar o elemento 1,1 em 1;

3.  Use as operações 2 e 3 para transformar todos os outros elementos da coluna em 0;

4.  Use a operação 1 para obter um elemento não nulo na posição 2,2 da matriz;

5.  Repita a partir do 2 até a matriz estar escalonada, alterando o passo 4 para a posição 3,3, 4,4 e assim por diante.

**8ª propridade dos determinantes - Matriz Inversa**
$det(A^{-1}) = [det(A)]^{-1} = \frac{1}{det(A)}$
Exemplo:
$$
A_{3\times3} =
\begin{bmatrix}
    -1 & 2 & 4  \\
    -2 & -2 & 0 \\
    1 & -2 & 1 \\
\end{bmatrix}  \\
\rightarrow det(A) = 30
$$

$$
A^{-1}_{3\times3} =
\begin{bmatrix}
    \frac{-1}{15} & \frac{-1}{3} & \frac{4}{15}  \\
    \frac{1}{15} & \frac{-1}{6} & \frac{-4}{15} \\
    \frac{1}{5} & 0 & \frac{1}{5} \\
\end{bmatrix}  \\
\rightarrow det(A^{-1}) = \frac{1}{det(A)} = \frac{1}{30}
$$

## Transposição de matrizes

Transpor uma matriz nada mais é que inverter suas colunas e linhas @hartmanMatrixTranspose2021. Mostraremos alguns exemplos dessa inversão e então ressaltaremos alguns fatos interessantes sobre a transposição e suas propriedades.

Seja 

$$
A = \begin{bmatrix}
    a & b & c \\
    d & e & f
\end{bmatrix}
$$

Então a transposta de $A$, $A^{t}$ é

$$
\begin{bmatrix}
    a & d \\
    b & e \\
    c & f
\end{bmatrix}
$$

Note que apenas "invertemos" as matrizes e as colunas. Aqui vai então nosso primeiro fato interessante.

Inverter uma matriz quadrada é apenas espelhar sua diagonal:

$$
B = \begin{bmatrix}
    1 & 5 & 7 \\
    9 & 2 & 4 \\
    8 & 0 & 3
\end{bmatrix} \Rightarrow B^{t} =
\begin{bmatrix}
    1 & 9 & 8 \\
    5 & 2 & 0 \\
    7 & 4 & 3
\end{bmatrix}
$$

Um outro fato interessante: uma matriz é chamada de *simétrica* se ela é igual à sua transposta.

Verifique se a matriz 

$$
C = \begin{bmatrix}
    2 & 1 & 2\\
    1 & 1 & 1\\
    2 & 1 & 0 
\end{bmatrix}
$$

é simétrica.

Iremos agora enunciar algumas *Propriedades da Transposição*: 

$$
\begin{aligned}
1.&~ (A^{t})^{t} = A \\
2.&~ (\lambda A)^{t} = \lambda A^{t} \\
3.&~ (AB)^{t} = B^t A^t ~~~~~ \text{Por que invertemos a ordem?} \\
4.&~ (A \pm B)^{t} = A^t \pm B^t \\
5.&~ (A^{-1})^{t} = (A^{t})^{-1}
\end{aligned}
$$

Encorajamos o leitor a tentar provar, ou pelo menos fornecer um exemplo, para cada uma dessas propriedades.

**9ª propriedade dos determinantes - Determinante da Transposta**
Seja $A^t$ a transposta da matriz $A$. $det(A^t) = det(A)$.
Exemplo:
$$
A_{3\times3} =
\begin{bmatrix}
    -1 & 2 & 4  \\
    -2 & -2 & 0 \\
    1 & -2 & 1 \\
\end{bmatrix}  \\
\rightarrow det(A) = 30
$$
$$
A^t_{3\times3} =
\begin{bmatrix}
    -1 & -2 & 1 \\
    2 & -2 & -2 \\
    4 & 0 & 1 \\
\end{bmatrix}  \\
\rightarrow det(A^t) = det(A) = 30
$$


## Material adicional {#sec-material-matrizes}

Para os curiosos, este vídeos sobre [Multiplicação de Matrizes](https://youtu.be/XkY2DOUCWMU), este sobre [Determinantes](https://www.youtube.com/watch?v=Ip3X9LOh2dk) e este sobre [Matrizes Inversas e a Identidade](https://youtu.be/uQhTuRlWMxw) do canal no YouTube [3blue1brown](https://www.youtube.com/@3blue1brown) (em inglês, com legendas em português) te darão uma intuição sobre o que estamos fazendo de fato quando multiplicamos matrizes.